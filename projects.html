<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<!-- Animate.css -->
<link rel="stylesheet" href="css/animate.css">

<title>Projects</title>
<!-- MathJax -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async>
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
	  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<!-- End MathJax -->
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="academic-experience.html">Academic&nbsp;Experience</a></div>
<div class="menu-item"><a href="projects.html" class="current">Projects</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1> Notable Projects</h1>
</div>
<h2>A Comprehensive Framework for Control of Complex Networks</h2>
<p>
  This framework consists of optimal driver node selection to achieve controllability of the network and choosing the method of calculation of the optimal input regarding the type of the optimization problem. In order to demonstrate our framework, an illustrative example of applying it to control people's opinions in a social network is provided below:
</p>
<p>
  The network we are going to investigate is a social network consisting of 62 people who are connected to each other. This network is undirected and weighted according to the level of communication between people. The people of this network are surveyed about a topic during a period. We intend to manipulate people's opinions about that topic.
    <p>
      First, we determine the nodes that have the ability to control the network with the lowest energy. The importance of each person for minimum-cost control of the network is shown in the left figure. The selected nodes of the network are highlighted in red in the right figure.
    </p>
  <figure>
    <img src="./images/node_selection.png" alt="DeepDDR" style="width:100%">
  </figure>
</p>

<p>
  According to the type of problem (discrete time and long-term control horizon), We choose the proper control method and apply the input to the driver nodes.</p>
<p>
  People's initial opinions (1 means extreme agreement and -1 means extreme disagreement) are shown in the left figure. After applying the inputs on the driver nodes, the opinion of the network goes towards the desired state, i.e. maximum agreement (right figure).
</p>
<figure>
  <img src="./images/opinion_control.png" alt="DeepDDR" style="width:100%">
</figure>
The source code for this project is available upon reasonable request.
<h2>Simulation of a Smart House </h2>
In this project, we will simulate a smart house equipped with IoT devices to control and monitor the lights, open and close a door, and regulate the home's temperature. A user interface dashboard is created in the ThingsBoard IoT platform in order to simulate the smart house. The data transferring is done via MQTT protocols.

Below is a sample of a designed dashboard in ThingsBoard. 
<figure>
  <img src="./images/Dashboard.png" alt="DeepDDR" style="width:75%", class="center">
</figure>
<p>
  To illustrate the data transfer between the server and the IoT dashboard, we run our simulation script. As a result of running the code temperature will fluctuate, the door will continue to close and open randomly, and the lights will turn on and off randomly.
  Below is the app log after running</p>
  <figure>
    <img src="./images/App_log.png" alt="DeepDDR" style="width:75%", class="center">
  </figure>
  The source code for this project is available on my <a href="https://github.com/SiavashShams/Simulation-of-a-Smart-House">[Github]</a>

  <h2>Reinforcement Learning Based Path Planning for a Robot </h2>
  <p>
    This project is about finding the optimal path between a start point and an endpoint in an environment with blocks. Reaching the end goal has a reward, and hitting or moving close to the obstacles has negative rewards (punishments). Also, there is little punishment for moving for the robot.
  </p>
  <figure>
    <img src="./images/RL.png" alt="DeepDDR" style="width:300px", class="center">
  </figure>
  In order to guide the robot in the environment, we will use the policy iteration method to obtain the value of each block in the environment. The robot will decide its next action based on the value of its neighbouring blocks (there are 8 neighbouring blocks in general, but this number changes if the robot is on the circumference of the environment). After applying the policy iteration algorithm, the value of each block is obtained as below. The black blocks with 0 value are obstacles, and the robot will receive a negative reward if it hits them. So the robot can choose the proper direction for its next step. 

<figure>
  <img src="./images/Value_map.png" alt="DeepDDR" style="width:100%", class="center">
</figure>
<p>
  The source code for this project is available on my <a href="https://github.com/SiavashShams/Reinforcement-Learning-Based-Path-Planning-for-a-Robot">[Github]</a>
</p>
<div id="toptitle">
  <h1>Selected Course Projects</h1>
</div>
<h2> DQN for OpenAI LunarLander-v2 </h2>

    <div class="project" style="background-image: url(images/Lunarlander.PNG); ">
      <div class="desc">
        <div class="con">
          <span>LunarLander-v2 learning how to land efficiently using DQN and DDQN for training DQN. This project can be found <a href="https://github.com/SiavashShams/DQN-for-OpenAI-LunarLander-v2" style="color: white"> Here</a>.
          </span>
        </div>
      </div>
    </div>
<h2> Generating Stuff with GANs and VAEs </h2>
    <div class="project" style="background-image: url(images/Gans.png);">
      <div class="desc">
        <div class="con">
          <span> Generating images in different contexts using GANs and Variational Autoencoders. This project can be found <a href="https://github.com/SiavashShams/Generating-Stuff-with-GANs-and-VAEs" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>

    <h2> Contextual embeddings Using RNNs </h2>
    <div class="project" style="background-image: url(images/stopingHate.jpg);">
      <div class="desc">
        <div class="con">
          <span> Using HateBert and two RNNs as its last trainable layers to classify context of the tweets in the dataset (0: hate tweets, 1: offensive tweets, 2: neutral tweets). This project can be found <a href="https://github.com/SiavashShams/Contextual-Embeddings-Using-HateBert-and-RNNs" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>

    <h2> Stock Market Prediction </h2>
    <div class="project" style="background-image: url(images/stock.jpg);">
      <div class="desc">
        <div class="con">
          <span> Predicting the price of Apple and Google stock using RNN, LSTM, GRU. This project can be found <a href="https://github.com/SiavashShams/Stock-Market-Prediction" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>

    <h2> Object Detection Using YOLOv5 </h2>
    <div class="project" style="background-image: url(images/Object_detection.jpg);">
      <div class="desc">
        <div class="con">
          <span> Detecting bocce balls and labeling their color. This project can be found <a href="https://github.com/SiavashShams/Object-Detection-Using-YOLOv5" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>

    <h2> Route Planning in Tehran with Dynamic Programming </h2>
    <div class="project" style="background-image: url(images/Routing.png);">
      <div class="desc">
        <div class="con">
          <span> Dynamic programming is used to determine the best (shortest) path between two desired points in the city of Tehran. This project can be found <a href="https://github.com/SiavashShams/Route-Planning-in-Tehran-with-Dynamic-Programming" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>

    <h2> Blood Sugar Level Control </h2>
    <div class="project" style="background-image: url(images/blood.jpg);">
      <div class="desc">
        <div class="con">
          <span> The blood sugar dynamics are modeled with an LTI system and we try to regulate this system. This project can be found <a href="https://github.com/SiavashShams/Blood-Sugar-Level-Control" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>
    
    <h2> EEG Signal Processing </h2>
    <div class="project" style="background-image: url(images/brain_waves.png);">
      <div class="desc">
        <div class="con">
          <span> In this project we try to analyse the brain waves during stages of the sleep and try to specify the stage of sleep for the unlabelled recorded signals. This project can be found <a href="https://github.com/SiavashShams/EEG-Signal-Processing" style="color: white"> Here</a>.
          <br>
          </span>
          
        </div>
      </div>
    </div>


</td>
</tr>
</table>
</body>
</html>
